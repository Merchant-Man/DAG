{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fbe9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import io\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "from datetime import timezone\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8ba6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file='/Users/aesocia/Documents/BGSI/DEV/dwh-dags/bclconvert_appsessions-2025-08-25.csv'\n",
    "API_BASE_URL = \"https://api.aps4.sh.basespace.illumina.com/v2/runs\"\n",
    "API_TOKEN = \"c8c09c39ab664017997f5c1caf4e49b9\"\n",
    "API_BASE = \"https://api.aps4.sh.basespace.illumina.com/v2\"\n",
    "df_app=pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca057a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3611b773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-26T10:26:57.080+0700\u001b[0m] {\u001b[34m974258736.py:\u001b[0m36} INFO\u001b[0m - üì¶ Page offset=0 | received 25 sessions\u001b[0m\n",
      "[\u001b[34m2025-08-26T10:26:58.085+0700\u001b[0m] {\u001b[34m974258736.py:\u001b[0m36} INFO\u001b[0m - üì¶ Page offset=25 | received 25 sessions\u001b[0m\n",
      "[\u001b[34m2025-08-26T10:26:58.087+0700\u001b[0m] {\u001b[34m974258736.py:\u001b[0m42} INFO\u001b[0m - ‚èπ Hit sessions older than cutoff; stopping.\u001b[0m\n",
      "[\u001b[34m2025-08-26T10:26:58.104+0700\u001b[0m] {\u001b[34m974258736.py:\u001b[0m108} INFO\u001b[0m - ‚úî Final DataFrame shape: (2, 17)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MAX_ROWS   = 1000   # hard cap of newest rows to collect\n",
    "PAGE_LIMIT = 25     # API hard cap\n",
    "SORT_BY    = \"DateCreated\"\n",
    "SORT_DIR   = \"Desc\"  # newest first\n",
    "\n",
    "# Optional: early stop once DateCreated < this value\n",
    "CURR_DS    = \"2025-08-20\"  # e.g., \"2025-08-25\"\n",
    "\n",
    "# ---------------------------\n",
    "# Run\n",
    "# ---------------------------\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Accept\": \"application/json\",\n",
    "}\n",
    "\n",
    "all_rows = []\n",
    "offset = 0\n",
    "\n",
    "while len(all_rows) < MAX_ROWS:\n",
    "    url = (\n",
    "        f\"{API_BASE}/appsessions\"\n",
    "        f\"?offset={offset}&limit={PAGE_LIMIT}\"\n",
    "        f\"&sortBy={SORT_BY}&sortDir={SORT_DIR}\"\n",
    "    )\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    resp.raise_for_status()\n",
    "    payload = resp.json() or {}\n",
    "    sessions = payload.get(\"Items\", []) or []\n",
    "\n",
    "    # Optional early stop if sessions are older than CURR_DS\n",
    "    if CURR_DS:\n",
    "        sessions = [s for s in sessions if s.get(\"DateCreated\", \"\") >= CURR_DS]\n",
    "        if not sessions:\n",
    "            break\n",
    "\n",
    "    for session in sessions:\n",
    "        if \"BCLConvert\" not in session.get(\"Name\", \"\"):\n",
    "            continue\n",
    "\n",
    "        session_id = session.get(\"Id\")\n",
    "        if not session_id:\n",
    "            continue\n",
    "\n",
    "        # Fetch session detail\n",
    "        detail_url = f\"{API_BASE}/appsessions/{session_id}\"\n",
    "        dresp = requests.get(detail_url, headers=headers)\n",
    "        if dresp.status_code != 200:\n",
    "            logger.warning(f\"‚ö†Ô∏è Detail fetch failed for {session_id}: {dresp.status_code}\")\n",
    "            continue\n",
    "        detail = dresp.json() or {}\n",
    "\n",
    "        props_items = detail.get(\"Properties\", {}).get(\"Items\", []) or []\n",
    "        properties = {i.get(\"Name\"): i.get(\"Content\") for i in props_items if i.get(\"Name\")}\n",
    "\n",
    "        run_items = []\n",
    "        for i in props_items:\n",
    "            if i.get(\"Name\") == \"Input.Runs\":\n",
    "                run_items = i.get(\"RunItems\", []) or []\n",
    "\n",
    "        for run in run_items:\n",
    "            all_rows.append({\n",
    "                \"RowType\": \"Run\",\n",
    "                \"SessionId\": session_id,\n",
    "                \"SessionName\": detail.get(\"Name\"),\n",
    "                \"DateCreated\": detail.get(\"DateCreated\"),\n",
    "                \"DateModified\": detail.get(\"DateModified\"),\n",
    "                \"ExecutionStatus\": detail.get(\"ExecutionStatus\"),\n",
    "                \"ICA_Link\": detail.get(\"HrefIcaAnalysis\"),\n",
    "                \"ICA_ProjectId\": properties.get(\"ICA.ProjectId\"),\n",
    "                \"WorkflowReference\": properties.get(\"ICA.WorkflowSessionUserReference\"),\n",
    "                \"RunId\": run.get(\"Id\"),\n",
    "                \"RunName\": run.get(\"Name\"),\n",
    "                \"PercentGtQ30\": run.get(\"SequencingStats\", {}).get(\"PercentGtQ30\"),\n",
    "                \"FlowcellBarcode\": run.get(\"FlowcellBarcode\"),\n",
    "                \"ReagentBarcode\": run.get(\"ReagentBarcode\"),\n",
    "                \"Status\": run.get(\"Status\"),\n",
    "                \"ExperimentName\": run.get(\"ExperimentName\"),\n",
    "                \"RunDateCreated\": run.get(\"DateCreated\"),\n",
    "            })\n",
    "\n",
    "            if len(all_rows) >= MAX_ROWS:\n",
    "                logger.info(f\"‚úÖ Reached max_rows={MAX_ROWS}. Stopping.\")\n",
    "                break\n",
    "\n",
    "        if len(all_rows) >= MAX_ROWS:\n",
    "            break\n",
    "\n",
    "    offset += PAGE_LIMIT\n",
    "# ---------------------------\n",
    "# Build DataFrame\n",
    "# ---------------------------\n",
    "df = pd.DataFrame(all_rows, columns=[\n",
    "    \"RowType\", \"SessionId\", \"SessionName\", \"DateCreated\", \"DateModified\",\n",
    "    \"ExecutionStatus\", \"ICA_Link\", \"ICA_ProjectId\", \"WorkflowReference\",\n",
    "    \"RunId\", \"RunName\", \"PercentGtQ30\", \"FlowcellBarcode\", \"ReagentBarcode\",\n",
    "    \"Status\", \"ExperimentName\", \"RunDateCreated\"\n",
    "])\n",
    "\n",
    "logger.info(f\"‚úî Final DataFrame shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03391245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    246246\n",
       "1    245245\n",
       "Name: RunId, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"RunId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d804963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4ba6646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-26T16:53:29.434+0700\u001b[0m] {\u001b[34m1136230620.py:\u001b[0m144} INFO\u001b[0m - ‚úî DataFrame shape before enrichment: (2, 17)\u001b[0m\n",
      "[\u001b[34m2025-08-26T16:53:29.688+0700\u001b[0m] {\u001b[34m1136230620.py:\u001b[0m175} INFO\u001b[0m - ‚úî Final DataFrame shape: (2, 18)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "def fetch_bclconvert_runs_with_yield(\n",
    "    api_base: str,\n",
    "    api_token: str,\n",
    "    *,\n",
    "    max_rows: int = 1000,\n",
    "    page_limit: int = 25,\n",
    "    sort_by: str = \"DateCreated\",\n",
    "    sort_dir: str = \"Desc\",\n",
    "    curr_ds: str | None = None,\n",
    "    logger: logging.Logger | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch newest BCLConvert Run sessions and enrich them with total_flowcell_yield_gbp.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    api_base : str\n",
    "        Base URL for the AppSessions API (e.g., https://api.example.com)\n",
    "    api_token : str\n",
    "        API token for AppSessions\n",
    "    stats_base : str\n",
    "        Base URL for sequencing stats API (e.g., https://api.example.com/runs)\n",
    "    max_rows : int\n",
    "        Hard cap of newest rows to collect\n",
    "    page_limit : int\n",
    "        API page size (server hard cap is 25)\n",
    "    sort_by : str\n",
    "        Field to sort by (default \"DateCreated\")\n",
    "    sort_dir : str\n",
    "        Sort direction (default \"Desc\" = newest first)\n",
    "    curr_ds : str | None\n",
    "        Optional cutoff, only include sessions where DateCreated >= curr_ds\n",
    "    logger : logging.Logger | None\n",
    "        Optional logger; if None, a default logger is created.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame of Run rows, including total_flowcell_yield_gbp column.\n",
    "    \"\"\"\n",
    "\n",
    "    if logger is None:\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "            stream=sys.stdout,\n",
    "        )\n",
    "        logger = logging.getLogger(\"bclconvert-fetch\")\n",
    "\n",
    "    all_rows = []\n",
    "    offset = 0\n",
    "\n",
    "    sessions_headers = {\n",
    "        \"Authorization\": f\"Bearer {api_token}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    while len(all_rows) < max_rows:\n",
    "        url = (\n",
    "            f\"{api_base}/appsessions\"\n",
    "            f\"?offset={offset}&limit={page_limit}\"\n",
    "            f\"&sortBy={sort_by}&sortDir={sort_dir}\"\n",
    "        )\n",
    "        resp = requests.get(url, headers=sessions_headers)\n",
    "        resp.raise_for_status()\n",
    "        payload = resp.json() or {}\n",
    "        sessions = payload.get(\"Items\", []) or []\n",
    "\n",
    "        if not sessions:\n",
    "            break\n",
    "\n",
    "        # Optional cutoff\n",
    "        if curr_ds:\n",
    "            sessions = [s for s in sessions if s.get(\"DateModified\", \"\") >= curr_ds]\n",
    "            if not sessions:\n",
    "                break\n",
    "\n",
    "        for session in sessions:\n",
    "            if \"BCLConvert\" not in session.get(\"Name\", \"\"):\n",
    "                continue\n",
    "\n",
    "            session_id = session.get(\"Id\")\n",
    "            if not session_id:\n",
    "                continue\n",
    "\n",
    "            # fetch detail\n",
    "            detail_url = f\"{api_base}/appsessions/{session_id}\"\n",
    "            dresp = requests.get(detail_url, headers=sessions_headers)\n",
    "            if dresp.status_code != 200:\n",
    "                logger.warning(f\"‚ö†Ô∏è Detail fetch failed for {session_id}: {dresp.status_code}\")\n",
    "                continue\n",
    "            detail = dresp.json() or {}\n",
    "\n",
    "            props_items = detail.get(\"Properties\", {}).get(\"Items\", []) or []\n",
    "            properties = {i.get(\"Name\"): i.get(\"Content\") for i in props_items if i.get(\"Name\")}\n",
    "\n",
    "            run_items = []\n",
    "            for i in props_items:\n",
    "                if i.get(\"Name\") == \"Input.Runs\":\n",
    "                    run_items = i.get(\"RunItems\", []) or []\n",
    "\n",
    "            for run in run_items:\n",
    "                all_rows.append({\n",
    "                    \"row_type\": \"Run\",\n",
    "                    \"session_id\": session_id,\n",
    "                    \"session_name\": detail.get(\"Name\"),\n",
    "                    \"date_created\": detail.get(\"DateCreated\"),\n",
    "                    \"date_modified\": detail.get(\"DateModified\"),\n",
    "                    \"execution_status\": detail.get(\"ExecutionStatus\"),\n",
    "                    \"ica_link\": detail.get(\"HrefIcaAnalysis\"),\n",
    "                    \"ica_project_id\": properties.get(\"ICA.ProjectId\"),\n",
    "                    \"workflow_reference\": properties.get(\"ICA.WorkflowSessionUserReference\"),\n",
    "                    \"run_id\": run.get(\"Id\"),\n",
    "                    \"run_name\": run.get(\"Name\"),\n",
    "                    \"percent_gt_q30\": run.get(\"SequencingStats\", {}).get(\"PercentGtQ30\"),\n",
    "                    \"flowcell_barcode\": run.get(\"FlowcellBarcode\"),\n",
    "                    \"reagent_barcode\": run.get(\"ReagentBarcode\"),\n",
    "                    \"status\": run.get(\"Status\"),\n",
    "                    \"experiment_name\": run.get(\"ExperimentName\"),\n",
    "                    \"run_date_created\": run.get(\"DateCreated\"),\n",
    "                })\n",
    "\n",
    "                if len(all_rows) >= max_rows:\n",
    "                    break\n",
    "            if len(all_rows) >= max_rows:\n",
    "                break\n",
    "\n",
    "        offset += page_limit\n",
    "\n",
    "    # ---- build DataFrame ----\n",
    "    df = pd.DataFrame(all_rows, columns=[\n",
    "        \"row_type\", \"session_id\", \"session_name\", \"date_created\", \"date_modified\",\n",
    "        \"execution_status\", \"ica_link\", \"ica_project_id\", \"workflow_reference\",\n",
    "        \"run_id\", \"run_name\", \"percent_gt_q30\", \"flowcell_barcode\", \"reagent_barcode\",\n",
    "        \"status\", \"experiment_name\", \"run_date_created\"\n",
    "    ])\n",
    "\n",
    "    logger.info(f\"‚úî DataFrame shape before enrichment: {df.shape}\")\n",
    "\n",
    "    # ---- enrich with sequencing stats ----\n",
    "    run_rows = df[df[\"row_type\"] == \"Run\"]\n",
    "\n",
    "    for _, row in run_rows.iterrows():\n",
    "        run_id = row.get(\"run_id\")\n",
    "        if not run_id or run_id.lower() == \"nan\":\n",
    "            continue\n",
    "\n",
    "        api_url = f\"{api_base}/runs/{run_id}/sequencingstats\"\n",
    "        stats_headers = {\n",
    "            \"x-access-token\": api_token,\n",
    "            \"Accept\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(api_url, headers=stats_headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            total_yield = data.get(\"YieldTotal\")\n",
    "\n",
    "            if total_yield is not None:\n",
    "                df.loc[\n",
    "                    (df[\"row_type\"] == \"Run\") & (df[\"run_id\"] == run_id),\n",
    "                    \"total_flowcell_yield_Gbp\"\n",
    "                ] = total_yield\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"‚ö†Ô∏è Failed fetching stats for {run_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    logger.info(f\"‚úî Final DataFrame shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "df = fetch_bclconvert_runs_with_yield(\n",
    "    api_base=API_BASE,\n",
    "    api_token=API_TOKEN,\n",
    "    curr_ds=\"2025-08-20\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2b353b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_type</th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_name</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>execution_status</th>\n",
       "      <th>ica_link</th>\n",
       "      <th>ica_project_id</th>\n",
       "      <th>workflow_reference</th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>percent_gt_q30</th>\n",
       "      <th>flowcell_barcode</th>\n",
       "      <th>reagent_barcode</th>\n",
       "      <th>status</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_date_created</th>\n",
       "      <th>total_flowcell_yield_Gbp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Run</td>\n",
       "      <td>259259</td>\n",
       "      <td>BCLConvert 08/22/2025 23:57:04Z</td>\n",
       "      <td>2025-08-22T23:57:05.0000000Z</td>\n",
       "      <td>2025-08-23T02:24:32.0000000Z</td>\n",
       "      <td>Complete</td>\n",
       "      <td>https://ica.illumina.com/ica/link/project/7feb...</td>\n",
       "      <td>7feb6619-714b-48f7-a7fd-75ad264f9c55</td>\n",
       "      <td>ws_LP2508211-P1_b823b3</td>\n",
       "      <td>246246</td>\n",
       "      <td>250821_A01856_0274_BHLMJMDSXF</td>\n",
       "      <td>89.5419</td>\n",
       "      <td>HLMJMDSXF</td>\n",
       "      <td>NV2432571-RGSBS</td>\n",
       "      <td>Complete</td>\n",
       "      <td>LP2508211-P1</td>\n",
       "      <td>2025-08-21T06:23:35.0000000Z</td>\n",
       "      <td>3650.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run</td>\n",
       "      <td>256256</td>\n",
       "      <td>BCLConvert 08/21/2025 01:50:00Z</td>\n",
       "      <td>2025-08-21T01:50:00.0000000Z</td>\n",
       "      <td>2025-08-21T04:08:42.0000000Z</td>\n",
       "      <td>Complete</td>\n",
       "      <td>https://ica.illumina.com/ica/link/project/7feb...</td>\n",
       "      <td>7feb6619-714b-48f7-a7fd-75ad264f9c55</td>\n",
       "      <td>ws_LP2508131-P2_cd272a</td>\n",
       "      <td>245245</td>\n",
       "      <td>250819_A01856_0273_BHKGCNDSXF</td>\n",
       "      <td>89.3399</td>\n",
       "      <td>HKGCNDSXF</td>\n",
       "      <td>NV4421056-RGSBS</td>\n",
       "      <td>Complete</td>\n",
       "      <td>LP2508131-P2</td>\n",
       "      <td>2025-08-19T08:17:14.0000000Z</td>\n",
       "      <td>3545.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_type session_id                     session_name  \\\n",
       "0      Run     259259  BCLConvert 08/22/2025 23:57:04Z   \n",
       "1      Run     256256  BCLConvert 08/21/2025 01:50:00Z   \n",
       "\n",
       "                   date_created                 date_modified  \\\n",
       "0  2025-08-22T23:57:05.0000000Z  2025-08-23T02:24:32.0000000Z   \n",
       "1  2025-08-21T01:50:00.0000000Z  2025-08-21T04:08:42.0000000Z   \n",
       "\n",
       "  execution_status                                           ica_link  \\\n",
       "0         Complete  https://ica.illumina.com/ica/link/project/7feb...   \n",
       "1         Complete  https://ica.illumina.com/ica/link/project/7feb...   \n",
       "\n",
       "                         ica_project_id      workflow_reference  run_id  \\\n",
       "0  7feb6619-714b-48f7-a7fd-75ad264f9c55  ws_LP2508211-P1_b823b3  246246   \n",
       "1  7feb6619-714b-48f7-a7fd-75ad264f9c55  ws_LP2508131-P2_cd272a  245245   \n",
       "\n",
       "                        run_name  percent_gt_q30 flowcell_barcode  \\\n",
       "0  250821_A01856_0274_BHLMJMDSXF         89.5419        HLMJMDSXF   \n",
       "1  250819_A01856_0273_BHKGCNDSXF         89.3399        HKGCNDSXF   \n",
       "\n",
       "   reagent_barcode    status experiment_name              run_date_created  \\\n",
       "0  NV2432571-RGSBS  Complete    LP2508211-P1  2025-08-21T06:23:35.0000000Z   \n",
       "1  NV4421056-RGSBS  Complete    LP2508131-P2  2025-08-19T08:17:14.0000000Z   \n",
       "\n",
       "   total_flowcell_yield_Gbp  \n",
       "0                   3650.02  \n",
       "1                   3545.24  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc73e874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-26T16:53:30.682+0700\u001b[0m] {\u001b[34m1136230620.py:\u001b[0m144} INFO\u001b[0m - ‚úî DataFrame shape before enrichment: (2, 17)\u001b[0m\n",
      "[\u001b[34m2025-08-26T16:53:30.954+0700\u001b[0m] {\u001b[34m1136230620.py:\u001b[0m175} INFO\u001b[0m - ‚úî Final DataFrame shape: (2, 18)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "def fetch_bclconvert_runs_with_yield(\n",
    "    api_base: str,\n",
    "    api_token: str,\n",
    "    *,\n",
    "    max_rows: int = 1000,\n",
    "    page_limit: int = 25,\n",
    "    sort_by: str = \"DateCreated\",\n",
    "    sort_dir: str = \"Desc\",\n",
    "    curr_ds: str | None = None,\n",
    "    logger: logging.Logger | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch newest BCLConvert Run sessions and enrich them with total_flowcell_yield_gbp.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    api_base : str\n",
    "        Base URL for the AppSessions API (e.g., https://api.example.com)\n",
    "    api_token : str\n",
    "        API token for AppSessions\n",
    "    stats_base : str\n",
    "        Base URL for sequencing stats API (e.g., https://api.example.com/runs)\n",
    "    max_rows : int\n",
    "        Hard cap of newest rows to collect\n",
    "    page_limit : int\n",
    "        API page size (server hard cap is 25)\n",
    "    sort_by : str\n",
    "        Field to sort by (default \"DateCreated\")\n",
    "    sort_dir : str\n",
    "        Sort direction (default \"Desc\" = newest first)\n",
    "    curr_ds : str | None\n",
    "        Optional cutoff, only include sessions where DateCreated >= curr_ds\n",
    "    logger : logging.Logger | None\n",
    "        Optional logger; if None, a default logger is created.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame of Run rows, including total_flowcell_yield_gbp column.\n",
    "    \"\"\"\n",
    "\n",
    "    if logger is None:\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "            stream=sys.stdout,\n",
    "        )\n",
    "        logger = logging.getLogger(\"bclconvert-fetch\")\n",
    "\n",
    "    all_rows = []\n",
    "    offset = 0\n",
    "\n",
    "    sessions_headers = {\n",
    "        \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    while len(all_rows) < max_rows:\n",
    "        url = (\n",
    "            f\"{api_base}/appsessions\"\n",
    "            f\"?offset={offset}&limit={page_limit}\"\n",
    "            f\"&sortBy={sort_by}&sortDir={sort_dir}\"\n",
    "        )\n",
    "        resp = requests.get(url, headers=sessions_headers)\n",
    "        resp.raise_for_status()\n",
    "        payload = resp.json() or {}\n",
    "        sessions = payload.get(\"Items\", []) or []\n",
    "\n",
    "        if not sessions:\n",
    "            break\n",
    "\n",
    "        # Optional cutoff\n",
    "        if curr_ds:\n",
    "            sessions = [s for s in sessions if s.get(\"DateModified\", \"\") >= curr_ds]\n",
    "            if not sessions:\n",
    "                break\n",
    "\n",
    "        for session in sessions:\n",
    "            if \"BCLConvert\" not in session.get(\"Name\", \"\"):\n",
    "                continue\n",
    "\n",
    "            session_id = session.get(\"Id\")\n",
    "            if not session_id:\n",
    "                continue\n",
    "\n",
    "            # fetch detail\n",
    "            detail_url = f\"{api_base}/appsessions/{session_id}\"\n",
    "            dresp = requests.get(detail_url, headers=sessions_headers)\n",
    "            if dresp.status_code != 200:\n",
    "                logger.warning(f\"‚ö†Ô∏è Detail fetch failed for {session_id}: {dresp.status_code}\")\n",
    "                continue\n",
    "            detail = dresp.json() or {}\n",
    "\n",
    "            props_items = detail.get(\"Properties\", {}).get(\"Items\", []) or []\n",
    "            properties = {i.get(\"Name\"): i.get(\"Content\") for i in props_items if i.get(\"Name\")}\n",
    "\n",
    "            run_items = []\n",
    "            for i in props_items:\n",
    "                if i.get(\"Name\") == \"Input.Runs\":\n",
    "                    run_items = i.get(\"RunItems\", []) or []\n",
    "\n",
    "            for run in run_items:\n",
    "                all_rows.append({\n",
    "                    \"row_type\": \"Run\",\n",
    "                    \"session_id\": session_id,\n",
    "                    \"session_name\": detail.get(\"Name\"),\n",
    "                    \"date_created\": detail.get(\"DateCreated\"),\n",
    "                    \"date_modified\": detail.get(\"DateModified\"),\n",
    "                    \"execution_status\": detail.get(\"ExecutionStatus\"),\n",
    "                    \"ica_link\": detail.get(\"HrefIcaAnalysis\"),\n",
    "                    \"ica_project_id\": properties.get(\"ICA.ProjectId\"),\n",
    "                    \"workflow_reference\": properties.get(\"ICA.WorkflowSessionUserReference\"),\n",
    "                    \"run_id\": run.get(\"Id\"),\n",
    "                    \"run_name\": run.get(\"Name\"),\n",
    "                    \"percent_gt_q30\": run.get(\"SequencingStats\", {}).get(\"PercentGtQ30\"),\n",
    "                    \"flowcell_barcode\": run.get(\"FlowcellBarcode\"),\n",
    "                    \"reagent_barcode\": run.get(\"ReagentBarcode\"),\n",
    "                    \"status\": run.get(\"Status\"),\n",
    "                    \"experiment_name\": run.get(\"ExperimentName\"),\n",
    "                    \"run_date_created\": run.get(\"DateCreated\"),\n",
    "                })\n",
    "\n",
    "                if len(all_rows) >= max_rows:\n",
    "                    break\n",
    "            if len(all_rows) >= max_rows:\n",
    "                break\n",
    "\n",
    "        offset += page_limit\n",
    "\n",
    "    # ---- build DataFrame ----\n",
    "    df = pd.DataFrame(all_rows, columns=[\n",
    "        \"row_type\", \"session_id\", \"session_name\", \"date_created\", \"date_modified\",\n",
    "        \"execution_status\", \"ica_link\", \"ica_project_id\", \"workflow_reference\",\n",
    "        \"run_id\", \"run_name\", \"percent_gt_q30\", \"flowcell_barcode\", \"reagent_barcode\",\n",
    "        \"status\", \"experiment_name\", \"run_date_created\"\n",
    "    ])\n",
    "\n",
    "    logger.info(f\"‚úî DataFrame shape before enrichment: {df.shape}\")\n",
    "\n",
    "    # ---- enrich with sequencing stats ----\n",
    "    run_rows = df[df[\"row_type\"] == \"Run\"]\n",
    "\n",
    "    for _, row in run_rows.iterrows():\n",
    "        run_id = row.get(\"run_id\")\n",
    "        if not run_id or run_id.lower() == \"nan\":\n",
    "            continue\n",
    "\n",
    "        api_url = f\"{api_base}/runs/{run_id}/sequencingstats\"\n",
    "        stats_headers = {\n",
    "            \"x-access-token\": api_token,\n",
    "            \"Accept\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(api_url, headers=stats_headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            total_yield = data.get(\"YieldTotal\")\n",
    "\n",
    "            if total_yield is not None:\n",
    "                df.loc[\n",
    "                    (df[\"row_type\"] == \"Run\") & (df[\"run_id\"] == run_id),\n",
    "                    \"total_flowcell_yield_Gbp\"\n",
    "                ] = total_yield\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"‚ö†Ô∏è Failed fetching stats for {run_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    logger.info(f\"‚úî Final DataFrame shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "df = fetch_bclconvert_runs_with_yield(\n",
    "    api_base=API_BASE,\n",
    "    api_token=API_TOKEN,\n",
    "    curr_ds=\"2025-08-20\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b7005d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c99add5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-26T16:55:43.027+0700\u001b[0m] {\u001b[34m1528369641.py:\u001b[0m53} INFO\u001b[0m - Cutoff filter 2025-08-10: kept 8/25 sessions in this page.\u001b[0m\n",
      "[\u001b[34m2025-08-26T16:55:45.756+0700\u001b[0m] {\u001b[34m1528369641.py:\u001b[0m53} INFO\u001b[0m - Cutoff filter 2025-08-10: kept 0/25 sessions in this page.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def _parse_iso(ts: str) -> Optional[datetime]:\n",
    "    \"\"\"Accepts 'YYYY-MM-DD' or ISO 'YYYY-MM-DDTHH:MM:SSZ' -> aware UTC datetime.\"\"\"\n",
    "    if not ts:\n",
    "        return None\n",
    "    try:\n",
    "        if \"T\" in ts:\n",
    "            return datetime.fromisoformat(ts.replace(\"Z\", \"+00:00\"))\n",
    "        return datetime.strptime(ts, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
    "    except Exception:\n",
    "        return None\n",
    "max_rows= 1000\n",
    "page_limit=25\n",
    "sort_by= \"DateCreated\"\n",
    "sort_dir= \"Desc\"\n",
    "ds=\"2025-08-10\"\n",
    "# ds = kwargs.get(\"ds\") or datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "cutoff = _parse_iso(ds)\n",
    "\n",
    "if logger is None:\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\", stream=sys.stdout)\n",
    "    logger = logging.getLogger(\"bclconvert-fetch\")\n",
    "\n",
    "run_rows: List[dict] = []\n",
    "biosample_rows: List[dict] = []\n",
    "offset = 0\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Accept\": \"application/json\",\n",
    "}\n",
    "\n",
    "while len(run_rows) < max_rows:\n",
    "    url = (\n",
    "        f\"{API_BASE}/appsessions\"\n",
    "        f\"?offset={offset}&limit={page_limit}&sortBy={sort_by}&sortDir={sort_dir}\"\n",
    "    )\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    resp.raise_for_status()\n",
    "    payload = resp.json() or {}\n",
    "    sessions = payload.get(\"Items\", []) or []\n",
    "    if not sessions:\n",
    "        logger.info(\"No sessions returned; stopping pagination.\")\n",
    "        break\n",
    "\n",
    "    # Filter by cutoff using DateModified (fallback to DateCreated)\n",
    "    if cutoff:\n",
    "        pre = len(sessions)\n",
    "        sessions = [\n",
    "            s for s in sessions\n",
    "            if ((_parse_iso(s.get(\"DateModified\")) or _parse_iso(s.get(\"DateCreated\"))) or datetime.min.replace(tzinfo=timezone.utc)) >= cutoff\n",
    "        ]\n",
    "        logger.info(f\"Cutoff filter {ds}: kept {len(sessions)}/{pre} sessions in this page.\")\n",
    "        if not sessions:\n",
    "            break\n",
    "\n",
    "    for session in sessions:\n",
    "        if \"BCLConvert\" not in (session.get(\"Name\") or \"\"):\n",
    "            continue\n",
    "        session_id = session.get(\"Id\")\n",
    "        if not session_id:\n",
    "            continue\n",
    "\n",
    "        # --- detail ---\n",
    "        detail_url = f\"{API_BASE}/appsessions/{session_id}\"\n",
    "        dresp = requests.get(detail_url, headers=headers)\n",
    "        if dresp.status_code != 200:\n",
    "            logger.warning(f\"‚ö†Ô∏è Detail fetch failed for {session_id}: {dresp.status_code}\")\n",
    "            continue\n",
    "        detail = dresp.json() or {}\n",
    "\n",
    "        props_items = (detail.get(\"Properties\") or {}).get(\"Items\", []) or []\n",
    "        properties = {i.get(\"Name\"): i.get(\"Content\") for i in props_items if i.get(\"Name\")}\n",
    "\n",
    "        run_items = []\n",
    "        for i in props_items:\n",
    "            if i.get(\"Name\") == \"Input.Runs\":\n",
    "                run_items = i.get(\"RunItems\", []) or []\n",
    "\n",
    "        # --- Run rows ---\n",
    "        for run in run_items:\n",
    "            run_rows.append({\n",
    "                \"session_id\": session_id,\n",
    "                \"session_name\": detail.get(\"Name\"),\n",
    "                \"date_created\": detail.get(\"DateCreated\"),\n",
    "                \"date_modified\": detail.get(\"DateModified\"),\n",
    "                \"execution_status\": detail.get(\"ExecutionStatus\"),\n",
    "                \"ica_link\": detail.get(\"HrefIcaAnalysis\"),\n",
    "                \"ica_project_id\": properties.get(\"ICA.ProjectId\"),\n",
    "                \"workflow_reference\": properties.get(\"ICA.WorkflowSessionUserReference\"),\n",
    "                \"run_id\": run.get(\"Id\"),\n",
    "                \"run_name\": run.get(\"Name\"),\n",
    "                \"percent_gt_q30\": (run.get(\"SequencingStats\") or {}).get(\"PercentGtQ30\"),\n",
    "                \"flowcell_barcode\": run.get(\"FlowcellBarcode\"),\n",
    "                \"reagent_barcode\": run.get(\"ReagentBarcode\"),\n",
    "                \"status\": run.get(\"Status\"),\n",
    "                \"experiment_name\": run.get(\"ExperimentName\"),\n",
    "                \"run_date_created\": run.get(\"DateCreated\"),\n",
    "            })\n",
    "\n",
    "            # ---- BioSample rows (Logs.Tail parsing) ----\n",
    "            logs_tail = next((i.get(\"Content\") for i in props_items if i.get(\"Name\") == \"Logs.Tail\"), \"\")\n",
    "            if logs_tail:\n",
    "                for line in logs_tail.splitlines():\n",
    "                    if \"Computed yield for biosample\" not in line:\n",
    "                        continue\n",
    "                    m = re.search(r\"Computed yield for biosample '([^']+)' \\(Id: (\\d+)\\): (\\d+)\\s+Bps\", line)\n",
    "                    if not m:\n",
    "                        continue\n",
    "                    biosample_name, biosample_id, yield_bps = m.group(1), m.group(2), m.group(3)\n",
    "\n",
    "                    gen_m = re.search(\n",
    "                        rf\"{re.escape(biosample_name)}.*?Generated new Sample:\\s+(\\d+)\",\n",
    "                        logs_tail,\n",
    "                        flags=re.DOTALL,\n",
    "                    )\n",
    "                    generated_sample_id = gen_m.group(1) if gen_m else None\n",
    "\n",
    "                    biosample_rows.append({\n",
    "                        \"session_id\": session_id,\n",
    "                        \"session_name\": detail.get(\"Name\"),\n",
    "                        \"date_created\": detail.get(\"DateCreated\"),\n",
    "                        \"run_name\": run.get(\"Name\"),\n",
    "                        \"experiment_name\": run.get(\"ExperimentName\"),\n",
    "                        \"run_date_created\": run.get(\"DateCreated\"),\n",
    "                        \"biosample_name\": biosample_name,\n",
    "                        \"biosample_id\": biosample_id,\n",
    "                        \"computed_yield_bps\": int(yield_bps),\n",
    "                        \"generated_sample_id\": generated_sample_id,\n",
    "                    })\n",
    "\n",
    "            if len(run_rows) >= max_rows:\n",
    "                break\n",
    "        if len(run_rows) >= max_rows:\n",
    "            break\n",
    "\n",
    "    offset += page_limit\n",
    "\n",
    "# ---- Build DataFrames ----\n",
    "df_runs = pd.DataFrame(run_rows)\n",
    "df_biosamples = pd.DataFrame(biosample_rows)\n",
    "\n",
    "# ---- Enrich Run rows with sequencing stats ----\n",
    "if not df_runs.empty:\n",
    "    for _, row in df_runs.iterrows():\n",
    "        run_id = row.get(\"run_id\")\n",
    "        if not run_id or str(run_id).lower() == \"nan\":\n",
    "            continue\n",
    "        api_url = f\"{API_BASE}/runs/{run_id}/sequencingstats\"\n",
    "        try:\n",
    "            response = requests.get(api_url, headers={\"x-access-token\": API_TOKEN, \"Accept\": \"application/json\"})\n",
    "            response.raise_for_status()\n",
    "            data = response.json() or {}\n",
    "            total_yield = data.get(\"YieldTotal\")\n",
    "            if total_yield is not None:\n",
    "                df_runs.loc[df_runs[\"run_id\"] == run_id, \"total_flowcell_yield_Gbps\"] = total_yield\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed fetching stats for run {run_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1061206b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_name</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>execution_status</th>\n",
       "      <th>ica_link</th>\n",
       "      <th>ica_project_id</th>\n",
       "      <th>workflow_reference</th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>percent_gt_q30</th>\n",
       "      <th>flowcell_barcode</th>\n",
       "      <th>reagent_barcode</th>\n",
       "      <th>status</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_date_created</th>\n",
       "      <th>total_flowcell_yield_Gbps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259259</td>\n",
       "      <td>BCLConvert 08/22/2025 23:57:04Z</td>\n",
       "      <td>2025-08-22T23:57:05.0000000Z</td>\n",
       "      <td>2025-08-23T02:24:32.0000000Z</td>\n",
       "      <td>Complete</td>\n",
       "      <td>https://ica.illumina.com/ica/link/project/7feb...</td>\n",
       "      <td>7feb6619-714b-48f7-a7fd-75ad264f9c55</td>\n",
       "      <td>ws_LP2508211-P1_b823b3</td>\n",
       "      <td>246246</td>\n",
       "      <td>250821_A01856_0274_BHLMJMDSXF</td>\n",
       "      <td>89.5419</td>\n",
       "      <td>HLMJMDSXF</td>\n",
       "      <td>NV2432571-RGSBS</td>\n",
       "      <td>Complete</td>\n",
       "      <td>LP2508211-P1</td>\n",
       "      <td>2025-08-21T06:23:35.0000000Z</td>\n",
       "      <td>3650.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256256</td>\n",
       "      <td>BCLConvert 08/21/2025 01:50:00Z</td>\n",
       "      <td>2025-08-21T01:50:00.0000000Z</td>\n",
       "      <td>2025-08-21T04:08:42.0000000Z</td>\n",
       "      <td>Complete</td>\n",
       "      <td>https://ica.illumina.com/ica/link/project/7feb...</td>\n",
       "      <td>7feb6619-714b-48f7-a7fd-75ad264f9c55</td>\n",
       "      <td>ws_LP2508131-P2_cd272a</td>\n",
       "      <td>245245</td>\n",
       "      <td>250819_A01856_0273_BHKGCNDSXF</td>\n",
       "      <td>89.3399</td>\n",
       "      <td>HKGCNDSXF</td>\n",
       "      <td>NV4421056-RGSBS</td>\n",
       "      <td>Complete</td>\n",
       "      <td>LP2508131-P2</td>\n",
       "      <td>2025-08-19T08:17:14.0000000Z</td>\n",
       "      <td>3545.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>254254</td>\n",
       "      <td>BCLConvert 08/17/2025 03:05:36Z</td>\n",
       "      <td>2025-08-17T03:05:37.0000000Z</td>\n",
       "      <td>2025-08-17T05:24:05.0000000Z</td>\n",
       "      <td>Complete</td>\n",
       "      <td>https://ica.illumina.com/ica/link/project/7feb...</td>\n",
       "      <td>7feb6619-714b-48f7-a7fd-75ad264f9c55</td>\n",
       "      <td>ws_LP2508131-P1_62549f</td>\n",
       "      <td>244245</td>\n",
       "      <td>250815_A01856_0272_BHKCWYDSXF</td>\n",
       "      <td>88.5928</td>\n",
       "      <td>HKCWYDSXF</td>\n",
       "      <td>NV4421036-RGSBS</td>\n",
       "      <td>Complete</td>\n",
       "      <td>LP2508131-P1</td>\n",
       "      <td>2025-08-15T09:33:11.0000000Z</td>\n",
       "      <td>3464.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253253</td>\n",
       "      <td>BCLConvert 08/15/2025 08:56:36Z</td>\n",
       "      <td>2025-08-15T08:56:36.0000000Z</td>\n",
       "      <td>2025-08-15T11:27:31.0000000Z</td>\n",
       "      <td>Complete</td>\n",
       "      <td>https://ica.illumina.com/ica/link/project/7feb...</td>\n",
       "      <td>7feb6619-714b-48f7-a7fd-75ad264f9c55</td>\n",
       "      <td>ws_LP2508121-P2_ae0335</td>\n",
       "      <td>242243</td>\n",
       "      <td>250813_A01856_0270_BHKFFKDSXF</td>\n",
       "      <td>90.1701</td>\n",
       "      <td>HKFFKDSXF</td>\n",
       "      <td>NV4421000-RGSBS</td>\n",
       "      <td>Complete</td>\n",
       "      <td>LP2508121-P2</td>\n",
       "      <td>2025-08-13T08:04:41.0000000Z</td>\n",
       "      <td>3642.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>251253</td>\n",
       "      <td>BCLConvert 08/13/2025 04:56:54Z</td>\n",
       "      <td>2025-08-13T04:56:54.0000000Z</td>\n",
       "      <td>2025-08-13T05:12:08.0000000Z</td>\n",
       "      <td>Aborted</td>\n",
       "      <td>https://ica.illumina.com/ica/link/project/7feb...</td>\n",
       "      <td>7feb6619-714b-48f7-a7fd-75ad264f9c55</td>\n",
       "      <td>ws_LP2508061-P1_9bbda7</td>\n",
       "      <td>240240</td>\n",
       "      <td>250809_A01856_0266_AHKCYGDSXF</td>\n",
       "      <td>58.6926</td>\n",
       "      <td>HKCYGDSXF</td>\n",
       "      <td>NV4421031-RGSBS</td>\n",
       "      <td>Failed</td>\n",
       "      <td>LP2508061-P1</td>\n",
       "      <td>2025-08-09T13:55:29.0000000Z</td>\n",
       "      <td>2929.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>251252</td>\n",
       "      <td>BCLConvert 08/13/2025 03:07:36Z</td>\n",
       "      <td>2025-08-13T03:07:36.0000000Z</td>\n",
       "      <td>2025-08-13T05:26:01.0000000Z</td>\n",
       "      <td>Complete</td>\n",
       "      <td>https://ica.illumina.com/ica/link/project/7feb...</td>\n",
       "      <td>7feb6619-714b-48f7-a7fd-75ad264f9c55</td>\n",
       "      <td>ws_LP2508111-P1_17e6fc</td>\n",
       "      <td>242242</td>\n",
       "      <td>250811_A01856_0269_AHKFGVDSXF</td>\n",
       "      <td>90.2297</td>\n",
       "      <td>HKFGVDSXF</td>\n",
       "      <td>NV4420999-RGSBS</td>\n",
       "      <td>Complete</td>\n",
       "      <td>LP2508111-P1</td>\n",
       "      <td>2025-08-11T09:04:58.0000000Z</td>\n",
       "      <td>3635.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>251251</td>\n",
       "      <td>BCLConvert 08/13/2025 03:04:00Z</td>\n",
       "      <td>2025-08-13T03:04:01.0000000Z</td>\n",
       "      <td>2025-08-13T05:23:05.0000000Z</td>\n",
       "      <td>Complete</td>\n",
       "      <td>https://ica.illumina.com/ica/link/project/7feb...</td>\n",
       "      <td>7feb6619-714b-48f7-a7fd-75ad264f9c55</td>\n",
       "      <td>ws_LP2508111-P2_62b3bf</td>\n",
       "      <td>241242</td>\n",
       "      <td>250811_A01856_0268_BHKF7LDSXF</td>\n",
       "      <td>90.1942</td>\n",
       "      <td>HKF7LDSXF</td>\n",
       "      <td>NV4421028-RGSBS</td>\n",
       "      <td>Complete</td>\n",
       "      <td>LP2508111-P2</td>\n",
       "      <td>2025-08-11T09:04:56.0000000Z</td>\n",
       "      <td>3706.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>250252</td>\n",
       "      <td>BCLConvert 08/11/2025 08:01:56Z</td>\n",
       "      <td>2025-08-11T08:01:56.0000000Z</td>\n",
       "      <td>2025-08-11T10:38:19.0000000Z</td>\n",
       "      <td>Complete</td>\n",
       "      <td>https://ica.illumina.com/ica/link/project/7feb...</td>\n",
       "      <td>7feb6619-714b-48f7-a7fd-75ad264f9c55</td>\n",
       "      <td>ws_LP2508061-P2_4af418</td>\n",
       "      <td>241241</td>\n",
       "      <td>250809_A01856_0267_BHKF57DSXF</td>\n",
       "      <td>90.8777</td>\n",
       "      <td>HKF57DSXF</td>\n",
       "      <td>NV4421040-RGSBS</td>\n",
       "      <td>Complete</td>\n",
       "      <td>LP2508061-P2</td>\n",
       "      <td>2025-08-09T13:55:30.0000000Z</td>\n",
       "      <td>3784.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  session_id                     session_name                  date_created  \\\n",
       "0     259259  BCLConvert 08/22/2025 23:57:04Z  2025-08-22T23:57:05.0000000Z   \n",
       "1     256256  BCLConvert 08/21/2025 01:50:00Z  2025-08-21T01:50:00.0000000Z   \n",
       "2     254254  BCLConvert 08/17/2025 03:05:36Z  2025-08-17T03:05:37.0000000Z   \n",
       "3     253253  BCLConvert 08/15/2025 08:56:36Z  2025-08-15T08:56:36.0000000Z   \n",
       "4     251253  BCLConvert 08/13/2025 04:56:54Z  2025-08-13T04:56:54.0000000Z   \n",
       "5     251252  BCLConvert 08/13/2025 03:07:36Z  2025-08-13T03:07:36.0000000Z   \n",
       "6     251251  BCLConvert 08/13/2025 03:04:00Z  2025-08-13T03:04:01.0000000Z   \n",
       "7     250252  BCLConvert 08/11/2025 08:01:56Z  2025-08-11T08:01:56.0000000Z   \n",
       "\n",
       "                  date_modified execution_status  \\\n",
       "0  2025-08-23T02:24:32.0000000Z         Complete   \n",
       "1  2025-08-21T04:08:42.0000000Z         Complete   \n",
       "2  2025-08-17T05:24:05.0000000Z         Complete   \n",
       "3  2025-08-15T11:27:31.0000000Z         Complete   \n",
       "4  2025-08-13T05:12:08.0000000Z          Aborted   \n",
       "5  2025-08-13T05:26:01.0000000Z         Complete   \n",
       "6  2025-08-13T05:23:05.0000000Z         Complete   \n",
       "7  2025-08-11T10:38:19.0000000Z         Complete   \n",
       "\n",
       "                                            ica_link  \\\n",
       "0  https://ica.illumina.com/ica/link/project/7feb...   \n",
       "1  https://ica.illumina.com/ica/link/project/7feb...   \n",
       "2  https://ica.illumina.com/ica/link/project/7feb...   \n",
       "3  https://ica.illumina.com/ica/link/project/7feb...   \n",
       "4  https://ica.illumina.com/ica/link/project/7feb...   \n",
       "5  https://ica.illumina.com/ica/link/project/7feb...   \n",
       "6  https://ica.illumina.com/ica/link/project/7feb...   \n",
       "7  https://ica.illumina.com/ica/link/project/7feb...   \n",
       "\n",
       "                         ica_project_id      workflow_reference  run_id  \\\n",
       "0  7feb6619-714b-48f7-a7fd-75ad264f9c55  ws_LP2508211-P1_b823b3  246246   \n",
       "1  7feb6619-714b-48f7-a7fd-75ad264f9c55  ws_LP2508131-P2_cd272a  245245   \n",
       "2  7feb6619-714b-48f7-a7fd-75ad264f9c55  ws_LP2508131-P1_62549f  244245   \n",
       "3  7feb6619-714b-48f7-a7fd-75ad264f9c55  ws_LP2508121-P2_ae0335  242243   \n",
       "4  7feb6619-714b-48f7-a7fd-75ad264f9c55  ws_LP2508061-P1_9bbda7  240240   \n",
       "5  7feb6619-714b-48f7-a7fd-75ad264f9c55  ws_LP2508111-P1_17e6fc  242242   \n",
       "6  7feb6619-714b-48f7-a7fd-75ad264f9c55  ws_LP2508111-P2_62b3bf  241242   \n",
       "7  7feb6619-714b-48f7-a7fd-75ad264f9c55  ws_LP2508061-P2_4af418  241241   \n",
       "\n",
       "                        run_name  percent_gt_q30 flowcell_barcode  \\\n",
       "0  250821_A01856_0274_BHLMJMDSXF         89.5419        HLMJMDSXF   \n",
       "1  250819_A01856_0273_BHKGCNDSXF         89.3399        HKGCNDSXF   \n",
       "2  250815_A01856_0272_BHKCWYDSXF         88.5928        HKCWYDSXF   \n",
       "3  250813_A01856_0270_BHKFFKDSXF         90.1701        HKFFKDSXF   \n",
       "4  250809_A01856_0266_AHKCYGDSXF         58.6926        HKCYGDSXF   \n",
       "5  250811_A01856_0269_AHKFGVDSXF         90.2297        HKFGVDSXF   \n",
       "6  250811_A01856_0268_BHKF7LDSXF         90.1942        HKF7LDSXF   \n",
       "7  250809_A01856_0267_BHKF57DSXF         90.8777        HKF57DSXF   \n",
       "\n",
       "   reagent_barcode    status experiment_name              run_date_created  \\\n",
       "0  NV2432571-RGSBS  Complete    LP2508211-P1  2025-08-21T06:23:35.0000000Z   \n",
       "1  NV4421056-RGSBS  Complete    LP2508131-P2  2025-08-19T08:17:14.0000000Z   \n",
       "2  NV4421036-RGSBS  Complete    LP2508131-P1  2025-08-15T09:33:11.0000000Z   \n",
       "3  NV4421000-RGSBS  Complete    LP2508121-P2  2025-08-13T08:04:41.0000000Z   \n",
       "4  NV4421031-RGSBS    Failed    LP2508061-P1  2025-08-09T13:55:29.0000000Z   \n",
       "5  NV4420999-RGSBS  Complete    LP2508111-P1  2025-08-11T09:04:58.0000000Z   \n",
       "6  NV4421028-RGSBS  Complete    LP2508111-P2  2025-08-11T09:04:56.0000000Z   \n",
       "7  NV4421040-RGSBS  Complete    LP2508061-P2  2025-08-09T13:55:30.0000000Z   \n",
       "\n",
       "   total_flowcell_yield_Gbps  \n",
       "0                    3650.02  \n",
       "1                    3545.24  \n",
       "2                    3464.07  \n",
       "3                    3642.22  \n",
       "4                    2929.15  \n",
       "5                    3635.83  \n",
       "6                    3706.36  \n",
       "7                    3784.02  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98ab8112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_name</th>\n",
       "      <th>date_created</th>\n",
       "      <th>run_name</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_date_created</th>\n",
       "      <th>biosample_name</th>\n",
       "      <th>biosample_id</th>\n",
       "      <th>computed_yield_bps</th>\n",
       "      <th>generated_sample_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259259</td>\n",
       "      <td>BCLConvert 08/22/2025 23:57:04Z</td>\n",
       "      <td>2025-08-22T23:57:05.0000000Z</td>\n",
       "      <td>250821_A01856_0274_BHLMJMDSXF</td>\n",
       "      <td>LP2508211-P1</td>\n",
       "      <td>2025-08-21T06:23:35.0000000Z</td>\n",
       "      <td>0C0305501C05</td>\n",
       "      <td>179182</td>\n",
       "      <td>113960848808</td>\n",
       "      <td>175175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259259</td>\n",
       "      <td>BCLConvert 08/22/2025 23:57:04Z</td>\n",
       "      <td>2025-08-22T23:57:05.0000000Z</td>\n",
       "      <td>250821_A01856_0274_BHLMJMDSXF</td>\n",
       "      <td>LP2508211-P1</td>\n",
       "      <td>2025-08-21T06:23:35.0000000Z</td>\n",
       "      <td>0C0306501C05</td>\n",
       "      <td>179188</td>\n",
       "      <td>144117706900</td>\n",
       "      <td>175175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259259</td>\n",
       "      <td>BCLConvert 08/22/2025 23:57:04Z</td>\n",
       "      <td>2025-08-22T23:57:05.0000000Z</td>\n",
       "      <td>250821_A01856_0274_BHLMJMDSXF</td>\n",
       "      <td>LP2508211-P1</td>\n",
       "      <td>2025-08-21T06:23:35.0000000Z</td>\n",
       "      <td>0C0307801C05</td>\n",
       "      <td>179195</td>\n",
       "      <td>152374189694</td>\n",
       "      <td>175175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259259</td>\n",
       "      <td>BCLConvert 08/22/2025 23:57:04Z</td>\n",
       "      <td>2025-08-22T23:57:05.0000000Z</td>\n",
       "      <td>250821_A01856_0274_BHLMJMDSXF</td>\n",
       "      <td>LP2508211-P1</td>\n",
       "      <td>2025-08-21T06:23:35.0000000Z</td>\n",
       "      <td>0C0306601C05</td>\n",
       "      <td>179191</td>\n",
       "      <td>111024782158</td>\n",
       "      <td>175175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259259</td>\n",
       "      <td>BCLConvert 08/22/2025 23:57:04Z</td>\n",
       "      <td>2025-08-22T23:57:05.0000000Z</td>\n",
       "      <td>250821_A01856_0274_BHLMJMDSXF</td>\n",
       "      <td>LP2508211-P1</td>\n",
       "      <td>2025-08-21T06:23:35.0000000Z</td>\n",
       "      <td>0C0306201C05</td>\n",
       "      <td>179199</td>\n",
       "      <td>111683073302</td>\n",
       "      <td>175175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>250252</td>\n",
       "      <td>BCLConvert 08/11/2025 08:01:56Z</td>\n",
       "      <td>2025-08-11T08:01:56.0000000Z</td>\n",
       "      <td>250809_A01856_0267_BHKF57DSXF</td>\n",
       "      <td>LP2508061-P2</td>\n",
       "      <td>2025-08-09T13:55:30.0000000Z</td>\n",
       "      <td>0C0291101C05</td>\n",
       "      <td>173230</td>\n",
       "      <td>167423941726</td>\n",
       "      <td>168216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>250252</td>\n",
       "      <td>BCLConvert 08/11/2025 08:01:56Z</td>\n",
       "      <td>2025-08-11T08:01:56.0000000Z</td>\n",
       "      <td>250809_A01856_0267_BHKF57DSXF</td>\n",
       "      <td>LP2508061-P2</td>\n",
       "      <td>2025-08-09T13:55:30.0000000Z</td>\n",
       "      <td>0C0290901C05</td>\n",
       "      <td>173224</td>\n",
       "      <td>173852167860</td>\n",
       "      <td>168216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>250252</td>\n",
       "      <td>BCLConvert 08/11/2025 08:01:56Z</td>\n",
       "      <td>2025-08-11T08:01:56.0000000Z</td>\n",
       "      <td>250809_A01856_0267_BHKF57DSXF</td>\n",
       "      <td>LP2508061-P2</td>\n",
       "      <td>2025-08-09T13:55:30.0000000Z</td>\n",
       "      <td>0C0287501C05</td>\n",
       "      <td>173242</td>\n",
       "      <td>139244565440</td>\n",
       "      <td>168216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>250252</td>\n",
       "      <td>BCLConvert 08/11/2025 08:01:56Z</td>\n",
       "      <td>2025-08-11T08:01:56.0000000Z</td>\n",
       "      <td>250809_A01856_0267_BHKF57DSXF</td>\n",
       "      <td>LP2508061-P2</td>\n",
       "      <td>2025-08-09T13:55:30.0000000Z</td>\n",
       "      <td>0C0287801C05</td>\n",
       "      <td>173228</td>\n",
       "      <td>125646266178</td>\n",
       "      <td>168216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>250252</td>\n",
       "      <td>BCLConvert 08/11/2025 08:01:56Z</td>\n",
       "      <td>2025-08-11T08:01:56.0000000Z</td>\n",
       "      <td>250809_A01856_0267_BHKF57DSXF</td>\n",
       "      <td>LP2508061-P2</td>\n",
       "      <td>2025-08-09T13:55:30.0000000Z</td>\n",
       "      <td>0C0289101C05</td>\n",
       "      <td>173244</td>\n",
       "      <td>140664832482</td>\n",
       "      <td>168216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id                     session_name                  date_created  \\\n",
       "0       259259  BCLConvert 08/22/2025 23:57:04Z  2025-08-22T23:57:05.0000000Z   \n",
       "1       259259  BCLConvert 08/22/2025 23:57:04Z  2025-08-22T23:57:05.0000000Z   \n",
       "2       259259  BCLConvert 08/22/2025 23:57:04Z  2025-08-22T23:57:05.0000000Z   \n",
       "3       259259  BCLConvert 08/22/2025 23:57:04Z  2025-08-22T23:57:05.0000000Z   \n",
       "4       259259  BCLConvert 08/22/2025 23:57:04Z  2025-08-22T23:57:05.0000000Z   \n",
       "..         ...                              ...                           ...   \n",
       "163     250252  BCLConvert 08/11/2025 08:01:56Z  2025-08-11T08:01:56.0000000Z   \n",
       "164     250252  BCLConvert 08/11/2025 08:01:56Z  2025-08-11T08:01:56.0000000Z   \n",
       "165     250252  BCLConvert 08/11/2025 08:01:56Z  2025-08-11T08:01:56.0000000Z   \n",
       "166     250252  BCLConvert 08/11/2025 08:01:56Z  2025-08-11T08:01:56.0000000Z   \n",
       "167     250252  BCLConvert 08/11/2025 08:01:56Z  2025-08-11T08:01:56.0000000Z   \n",
       "\n",
       "                          run_name experiment_name  \\\n",
       "0    250821_A01856_0274_BHLMJMDSXF    LP2508211-P1   \n",
       "1    250821_A01856_0274_BHLMJMDSXF    LP2508211-P1   \n",
       "2    250821_A01856_0274_BHLMJMDSXF    LP2508211-P1   \n",
       "3    250821_A01856_0274_BHLMJMDSXF    LP2508211-P1   \n",
       "4    250821_A01856_0274_BHLMJMDSXF    LP2508211-P1   \n",
       "..                             ...             ...   \n",
       "163  250809_A01856_0267_BHKF57DSXF    LP2508061-P2   \n",
       "164  250809_A01856_0267_BHKF57DSXF    LP2508061-P2   \n",
       "165  250809_A01856_0267_BHKF57DSXF    LP2508061-P2   \n",
       "166  250809_A01856_0267_BHKF57DSXF    LP2508061-P2   \n",
       "167  250809_A01856_0267_BHKF57DSXF    LP2508061-P2   \n",
       "\n",
       "                 run_date_created biosample_name biosample_id  \\\n",
       "0    2025-08-21T06:23:35.0000000Z   0C0305501C05       179182   \n",
       "1    2025-08-21T06:23:35.0000000Z   0C0306501C05       179188   \n",
       "2    2025-08-21T06:23:35.0000000Z   0C0307801C05       179195   \n",
       "3    2025-08-21T06:23:35.0000000Z   0C0306601C05       179191   \n",
       "4    2025-08-21T06:23:35.0000000Z   0C0306201C05       179199   \n",
       "..                            ...            ...          ...   \n",
       "163  2025-08-09T13:55:30.0000000Z   0C0291101C05       173230   \n",
       "164  2025-08-09T13:55:30.0000000Z   0C0290901C05       173224   \n",
       "165  2025-08-09T13:55:30.0000000Z   0C0287501C05       173242   \n",
       "166  2025-08-09T13:55:30.0000000Z   0C0287801C05       173228   \n",
       "167  2025-08-09T13:55:30.0000000Z   0C0289101C05       173244   \n",
       "\n",
       "     computed_yield_bps generated_sample_id  \n",
       "0          113960848808              175175  \n",
       "1          144117706900              175175  \n",
       "2          152374189694              175175  \n",
       "3          111024782158              175175  \n",
       "4          111683073302              175175  \n",
       "..                  ...                 ...  \n",
       "163        167423941726              168216  \n",
       "164        173852167860              168216  \n",
       "165        139244565440              168216  \n",
       "166        125646266178              168216  \n",
       "167        140664832482              168216  \n",
       "\n",
       "[168 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_biosamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a4b27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://ica.illumina.com/ica/rest/api\"\n",
    "PROJECT_ID = \"7feb6619-714b-48f7-a7fd-75ad264f9c55\"\n",
    "API_KEY=\"04LlMKg4K0asFGREmIXhucZ3IV2Hinx\"\n",
    "\n",
    "curr_ds=\"2025-05-21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "270a40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_download_url(api_key: str, project_id: str, file_id: str) -> str:\n",
    "    url = f\"{BASE_URL}/projects/{project_id}/data/{file_id}:createDownloadUrl\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/vnd.illumina.v3+json\",\n",
    "        \"X-API-Key\": api_key\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, data='')\n",
    "    response.raise_for_status()\n",
    "    return response.json().get(\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d490cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-26T13:49:36.196+0700\u001b[0m] {\u001b[34m3112584711.py:\u001b[0m17} INFO\u001b[0m - Fetching analyses for: 2025-05-21\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:49:36.198+0700\u001b[0m] {\u001b[34m3112584711.py:\u001b[0m27} INFO\u001b[0m - Requesting URL: https://ica.illumina.com/ica/rest/api/projects/7feb6619-714b-48f7-a7fd-75ad264f9c55/analyses?pageSize=100&pageOffset=0&sort=reference%20desc\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:49:38.013+0700\u001b[0m] {\u001b[34m3112584711.py:\u001b[0m33} INFO\u001b[0m - Fetched 100 analyses (offset 0)\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:49:38.014+0700\u001b[0m] {\u001b[34m3112584711.py:\u001b[0m27} INFO\u001b[0m - Requesting URL: https://ica.illumina.com/ica/rest/api/projects/7feb6619-714b-48f7-a7fd-75ad264f9c55/analyses?pageSize=100&pageOffset=100&sort=reference%20desc\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:49:41.320+0700\u001b[0m] {\u001b[34m3112584711.py:\u001b[0m33} INFO\u001b[0m - Fetched 100 analyses (offset 100)\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:49:41.321+0700\u001b[0m] {\u001b[34m3112584711.py:\u001b[0m27} INFO\u001b[0m - Requesting URL: https://ica.illumina.com/ica/rest/api/projects/7feb6619-714b-48f7-a7fd-75ad264f9c55/analyses?pageSize=100&pageOffset=200&sort=reference%20desc\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:49:43.979+0700\u001b[0m] {\u001b[34m3112584711.py:\u001b[0m33} INFO\u001b[0m - Fetched 68 analyses (offset 200)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def parse_iso_utc(ts: str) -> datetime:\n",
    "    # e.g. \"2025-08-23T02:07:00Z\" -> aware datetime\n",
    "    return datetime.fromisoformat(ts.replace(\"Z\", \"+00:00\"))\n",
    "\n",
    "analyses = []\n",
    "page_size = 100\n",
    "page_offset = 0\n",
    "\n",
    "HEADERS = {\n",
    "    \"accept\": \"application/vnd.illumina.v3+json\",\n",
    "    \"X-API-Key\": API_KEY\n",
    "}\n",
    "\n",
    "logger.info(f\"Fetching analyses for: {curr_ds}\")\n",
    "\n",
    "# Build UTC cutoff at start of day\n",
    "cutoff = datetime.strptime(curr_ds, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
    "\n",
    "while True:\n",
    "    url = (\n",
    "        f\"{BASE_URL}/projects/{PROJECT_ID}/analyses\"\n",
    "        f\"?pageSize={page_size}&pageOffset={page_offset}&sort=reference%20desc\"\n",
    "    )\n",
    "    logger.info(f\"Requesting URL: {url}\")\n",
    "    resp = requests.get(url, headers=HEADERS)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    items = data.get(\"items\", [])\n",
    "    logger.info(f\"Fetched {len(items)} analyses (offset {page_offset})\")\n",
    "\n",
    "    # Keep only those with timeModified >= cutoff\n",
    "    for a in items:\n",
    "        tm = a.get(\"timeModified\")\n",
    "        if not tm:\n",
    "            continue\n",
    "        if parse_iso_utc(tm) >= cutoff:\n",
    "            analyses.append(a)\n",
    "\n",
    "    if len(items) < page_size:\n",
    "        break\n",
    "    page_offset += page_size\n",
    "\n",
    "if not analyses:\n",
    "    logger.info(\"No analyses found that meet timeModified cutoff.\")\n",
    "    latest_analyses = []\n",
    "else:\n",
    "    # Sort by timeModified (latest first)\n",
    "    latest_analyses = sorted(\n",
    "        analyses,\n",
    "        key=lambda a: parse_iso_utc(a[\"timeModified\"]),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "# latest_analyses now has only items with timeModified >= curr_ds, newest first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01775fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-26T13:55:02.991+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2508211-P1_b823b3_04e691-64321e29-bf95-42e0-9337-118876056dbf\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:05.464+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2508131-P2_cd272a_8faf5b-c79b78eb-da2c-4fc8-9194-322e7dbc82ab\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:07.819+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2508131-P1_62549f_199e16-f3b4d819-aabf-42a8-96fc-bd1d1cd93e63\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:10.079+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2508121-P2_ae0335_382f7b-a0729fcd-d498-4cb7-84b4-caaa3c10f447\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:12.902+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2508061-P1_9bbda7_194252-3e8f92e0-e3b9-458a-bde7-f85b6a840bdd\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:15.434+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2508111-P1_17e6fc_3f190f-a4777f3b-7300-4b90-975e-b61f697c36eb\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:17.763+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2508111-P2_62b3bf_900325-52f148ee-df6b-4cda-a890-e3611b5aabae\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:20.137+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2508061-P2_4af418_6075cf-833705d3-889e-477d-9c9d-4a4c40fe20fc\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:22.688+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2507231-P1_Redo_d2d85d_7c32ca-515ef2ac-42cd-48a4-90eb-c1aa8ca60e8c\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:25.266+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2507252-P2_89b03e_bb27f4-e93f4536-33ac-4263-b514-5627bdad6cbb\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:27.893+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2507281-P1_e270c0_fd7420-5e1a2e05-abd5-445d-ab78-b32cf00406fe\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:30.291+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2507281-P2_42c312_e41e31-20012644-128b-47f8-950d-9a4ca64255d1\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:32.975+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2507252-P1_01b3da_0e88db-b12d8dc4-de1b-48dc-a734-700a823f2d09\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:35.547+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2507251-P2_e32aa7_3aecb8-de2cf6c7-6a2c-47ed-908a-bc5dc7d91ac3\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:38.109+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2507231-P2_63c87f_6acdff-2a1b8314-890a-40d9-a3e4-20dbcf5408a0\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:40.612+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2504281-P1_Redo_a4a8f8_212264-0e4fab24-a304-499b-8964-5a46c2f2df5e\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:43.183+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2507231-P2_83a335_d124d5-f66f45ab-a196-455a-800a-b084df5333cf\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:44.285+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2507251-P1_615d74_648ff1-41b1fc11-c1ee-4b6a-af47-922b83afdf49\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:46.732+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2505151-P2-Redo_a59329_84d18b-47301902-e39c-440f-85a0-9629fe671502\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:49.030+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2505151-P1-Redo_74bab2_ac0c72-e13346ca-66cc-472c-b9e9-7cc7588d27f5\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:51.497+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2505201-P2_1cf7fb_4e7c14-bd572f87-2046-45c2-b1e8-411ce7057242\u001b[0m\n",
      "[\u001b[34m2025-08-26T13:55:54.012+0700\u001b[0m] {\u001b[34m3034486776.py:\u001b[0m16} INFO\u001b[0m - Checking analysis reference: LP2505201-P1_51d305_68db2a-e671b25a-7109-44e6-bd26-25c5d69d554b\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "def create_download_url(api_key: str, project_id: str, file_id: str, BASE_URL:str) -> str:\n",
    "    url = f\"{BASE_URL}/projects/{project_id}/data/{file_id}:createDownloadUrl\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/vnd.illumina.v3+json\",\n",
    "        \"X-API-Key\": api_key\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, data='')\n",
    "    response.raise_for_status()\n",
    "    return response.json().get(\"url\")\n",
    "\n",
    "for analysis in latest_analyses:\n",
    "    reference = analysis.get(\"reference\")\n",
    "    logger.info(f\"Checking analysis reference: {reference}\")\n",
    "    if not reference:\n",
    "        continue\n",
    "\n",
    "    match = re.search(r\"(LP[-_]?\\d{7}(?:-P\\d)?(?:[-_](?:rerun|redo))?)\", str(reference), re.IGNORECASE)\n",
    "    if not match:\n",
    "        logger.warning(f\"Could not extract id_library from {reference}\")\n",
    "        continue\n",
    "    id_library = match.group(1)\n",
    "\n",
    "    # --- Handle Demultiplex_Stats.csv ---\n",
    "    demux_file_path = f\"/ilmn-analyses/{reference}/output/Reports/Demultiplex_Stats.csv\"\n",
    "    demux_encoded = urllib.parse.quote(demux_file_path)\n",
    "\n",
    "    demux_query = (\n",
    "        f\"{BASE_URL}/projects/{PROJECT_ID}/data\"\n",
    "        f\"?filePath={demux_encoded}\"\n",
    "        f\"&filenameMatchMode=EXACT\"\n",
    "        f\"&filePathMatchMode=STARTS_WITH_CASE_INSENSITIVE\"\n",
    "        f\"&status=AVAILABLE&type=FILE\"\n",
    "    )\n",
    "\n",
    "    demux_response = requests.get(demux_query, headers=HEADERS)\n",
    "    demux_response.raise_for_status()\n",
    "    demux_items = demux_response.json().get(\"items\", [])\n",
    "\n",
    "    if demux_items:\n",
    "        file_id = demux_items[0][\"data\"][\"id\"]\n",
    "        download_url = create_download_url(API_KEY, PROJECT_ID, file_id, BASE_URL)\n",
    "        response = requests.get(download_url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # === Add id_library column ===\n",
    "        csv_buf = io.StringIO(response.content.decode(\"utf-8\"))\n",
    "        df = pd.read_csv(csv_buf)\n",
    "        df[\"id_library\"] = id_library  # append new column\n",
    "\n",
    "        # Convert back to CSV bytes\n",
    "        csv_bytes = df.to_csv(index=False).encode(\"utf-8\")\n",
    "\n",
    "        # Upload to S3\n",
    "        s3_key = f\"{object_path_prefix}/{reference}/{id_library}_Demultiplex_Stats.csv\"\n",
    "        s3.load_bytes(\n",
    "            bytes_data=csv_bytes,\n",
    "            key=s3_key,\n",
    "            bucket_name=bucket_name,\n",
    "            replace=True\n",
    "        )\n",
    "        logger.info(f\"Uploaded Demultiplex_Stats with id_library to: s3://{bucket_name}/{s3_key}\")\n",
    "    else:\n",
    "        logger.info(f\"Demultiplex_Stats.csv not found for {reference}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d491cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5940c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LP2505201-P1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Quality_Metrics.csv ---\n",
    "quality_file_path = f\"/ilmn-analyses/{reference}/output/Reports/Quality_Metrics.csv\"\n",
    "quality_encoded = urllib.parse.quote(quality_file_path)\n",
    "\n",
    "quality_query = (\n",
    "    f\"{BASE_URL}/projects/{PROJECT_ID}/data\"\n",
    "    f\"?filePath={quality_encoded}\"\n",
    "    f\"&filenameMatchMode=EXACT\"\n",
    "    f\"&filePathMatchMode=STARTS_WITH_CASE_INSENSITIVE\"\n",
    "    f\"&status=AVAILABLE&type=FILE\"\n",
    ")\n",
    "\n",
    "quality_response = requests.get(quality_query, headers=HEADERS)\n",
    "quality_response.raise_for_status()\n",
    "quality_items = quality_response.json().get(\"items\", [])\n",
    "\n",
    "if quality_items:\n",
    "    file_id = quality_items[0][\"data\"][\"id\"]\n",
    "    # NOTE: your create_download_url requires BASE_URL param\n",
    "    download_url = create_download_url(API_KEY, PROJECT_ID, file_id, BASE_URL)\n",
    "    response = requests.get(download_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Add id_library column\n",
    "    q_csv_buf = io.StringIO(response.content.decode(\"utf-8\"))\n",
    "    q_df = pd.read_csv(q_csv_buf)\n",
    "    q_df[\"id_library\"] = id_library  # appended as last column\n",
    "\n",
    "    # Convert back to CSV bytes\n",
    "    q_csv_bytes = q_df.to_csv(index=False).encode(\"utf-8\")\n",
    "\n",
    "    # Final S3 key format: illumina/qs/{file_id}/Quality_Metrics.csv\n",
    "    qs_s3_key = f\"illumina/qs/{file_id}/Quality_Metrics.csv\"\n",
    "    s3.load_bytes(\n",
    "        bytes_data=q_csv_bytes,\n",
    "        key=qs_s3_key,\n",
    "        bucket_name=\"bgsi-data-dwh-bronze\",\n",
    "        replace=True\n",
    "    )\n",
    "    logger.info(f\"Uploaded Quality_Metrics (with id_library) to: s3://bgsi-data-dwh-bronze/{qs_s3_key}\")\n",
    "else:\n",
    "    logger.info(f\"Quality_Metrics.csv not found for {reference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a4379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6079bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import urllib.parse\n",
    "from typing import Dict, Any, List\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "def sync_ica_qc_to_s3(\n",
    "    *,                     # \"YYYY-MM-DD\"\n",
    "    API_KEY: str,\n",
    "    PROJECT_ID: str,\n",
    "    BASE_URL: str,                    # e.g. \"https://ica.illumina.com/ica/rest/api\"\n",
    "    bucket_name: str,                 # destination bucket for Demux\n",
    "    object_path_prefix: str,          # prefix for Demux (e.g. \"illumina/demux\")\n",
    "    s3_hook,                          # Airflow S3Hook instance\n",
    "    logger,                            # Airflow logger\n",
    "    **kwargs\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch ICA analyses (timeModified >= curr_ds), pull Demultiplex_Stats.csv and Quality_Metrics.csv,\n",
    "    append id_library column, and upload to S3.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "          \"analyses_considered\": int,\n",
    "          \"analyses_processed\": int,\n",
    "          \"demux_uploaded\": int,\n",
    "          \"quality_uploaded\": int,\n",
    "          \"per_analysis\": [{ \"reference\": str, \"demux\": \"uploaded|not_found|error\", \"quality\": \"uploaded|not_found|error\" }, ...]\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- helpers ----------\n",
    "    def create_download_url(api_key: str, project_id: str, file_id: str, base_url: str) -> str:\n",
    "        url = f\"{base_url}/projects/{project_id}/data/{file_id}:createDownloadUrl\"\n",
    "        headers = {\n",
    "            \"accept\": \"application/vnd.illumina.v3+json\",\n",
    "            \"X-API-Key\": api_key\n",
    "        }\n",
    "        r = requests.post(url, headers=headers, data=\"\")\n",
    "        r.raise_for_status()\n",
    "        return r.json().get(\"url\")\n",
    "\n",
    "    def parse_iso_utc(ts: str) -> datetime:\n",
    "        return datetime.fromisoformat(ts.replace(\"Z\", \"+00:00\"))\n",
    "\n",
    "    LP_REGEX = re.compile(r\"(LP[-_]?\\d{7}(?:-P\\d)?(?:[-_](?:rerun|redo))?)\", re.IGNORECASE)\n",
    "\n",
    "    def lookup_file_by_path(file_path: str) -> List[dict]:\n",
    "        encoded = urllib.parse.quote(file_path)\n",
    "        q = (\n",
    "            f\"{BASE_URL}/projects/{PROJECT_ID}/data\"\n",
    "            f\"?filePath={encoded}\"\n",
    "            f\"&filenameMatchMode=EXACT\"\n",
    "            f\"&filePathMatchMode=STARTS_WITH_CASE_INSENSITIVE\"\n",
    "            f\"&status=AVAILABLE&type=FILE\"\n",
    "        )\n",
    "        rr = requests.get(q, headers=HEADERS)\n",
    "        rr.raise_for_status()\n",
    "        return rr.json().get(\"items\", [])\n",
    "\n",
    "    def download_csv_bytes(file_id: str) -> bytes:\n",
    "        url = create_download_url(API_KEY, PROJECT_ID, file_id, BASE_URL)\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        return r.content\n",
    "\n",
    "    def add_id_library(csv_bytes: bytes, id_library: str) -> bytes:\n",
    "        buf = io.StringIO(csv_bytes.decode(\"utf-8\"))\n",
    "        df = pd.read_csv(buf)\n",
    "        df[\"id_library\"] = id_library\n",
    "        return df.to_csv(index=False).encode(\"utf-8\")\n",
    "\n",
    "    # ---------- fetch analyses (filtered by timeModified >= cutoff) ----------\n",
    "    HEADERS = {\n",
    "        \"accept\": \"application/vnd.illumina.v3+json\",\n",
    "        \"X-API-Key\": API_KEY\n",
    "    }\n",
    "    cutoff = datetime.strptime(kwargs.get(\"ds\"), \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
    "\n",
    "    analyses: List[dict] = []\n",
    "    page_size = 100\n",
    "    page_offset = 0\n",
    "\n",
    "    logger.info(f\"[ICA] Fetching analyses updated on/after {curr_ds} (UTC start-of-day cutoff)\")\n",
    "\n",
    "    while True:\n",
    "        url = (\n",
    "            f\"{BASE_URL}/projects/{PROJECT_ID}/analyses\"\n",
    "            f\"?pageSize={page_size}&pageOffset={page_offset}&sort=reference%20desc\"\n",
    "        )\n",
    "        logger.info(f\"[ICA] GET {url}\")\n",
    "        resp = requests.get(url, headers=HEADERS)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        items = data.get(\"items\", [])\n",
    "\n",
    "        logger.info(f\"[ICA] Page offset {page_offset}: {len(items)} analyses\")\n",
    "\n",
    "        for a in items:\n",
    "            tm = a.get(\"timeModified\")\n",
    "            if tm and parse_iso_utc(tm) >= cutoff:\n",
    "                analyses.append(a)\n",
    "\n",
    "        if len(items) < page_size:\n",
    "            break\n",
    "        page_offset += page_size\n",
    "\n",
    "    latest_analyses = sorted(\n",
    "        analyses, key=lambda a: parse_iso_utc(a[\"timeModified\"]), reverse=True\n",
    "    ) if analyses else []\n",
    "\n",
    "    # ---------- process each analysis ----------\n",
    "    summary = {\n",
    "        \"analyses_considered\": len(latest_analyses),\n",
    "        \"analyses_processed\": 0,\n",
    "        \"demux_uploaded\": 0,\n",
    "        \"quality_uploaded\": 0,\n",
    "        \"per_analysis\": []\n",
    "    }\n",
    "\n",
    "    for analysis in latest_analyses:\n",
    "        reference = analysis.get(\"reference\")\n",
    "        if not reference:\n",
    "            continue\n",
    "\n",
    "        status_row = {\"reference\": reference, \"demux\": \"not_found\", \"quality\": \"not_found\"}\n",
    "\n",
    "        m = LP_REGEX.search(str(reference))\n",
    "        if not m:\n",
    "            logger.warning(f\"[ICA] Could not extract id_library from reference: {reference}\")\n",
    "            summary[\"per_analysis\"].append(status_row)\n",
    "            continue\n",
    "        id_library = m.group(1)\n",
    "\n",
    "        # --- Demultiplex_Stats.csv ---\n",
    "        try:\n",
    "            demux_path = f\"/ilmn-analyses/{reference}/output/Reports/Demultiplex_Stats.csv\"\n",
    "            demux_items = lookup_file_by_path(demux_path)\n",
    "\n",
    "            if demux_items:\n",
    "                demux_file_id = demux_items[0][\"data\"][\"id\"]\n",
    "                raw_bytes = download_csv_bytes(demux_file_id)\n",
    "                out_bytes = add_id_library(raw_bytes, id_library)\n",
    "\n",
    "                demux_s3_key = f\"{object_path_prefix}/{reference}/{id_library}_Demultiplex_Stats.csv\"\n",
    "                s3_hook.load_bytes(\n",
    "                    bytes_data=out_bytes,\n",
    "                    key=demux_s3_key,\n",
    "                    bucket_name=bucket_name,\n",
    "                    replace=True\n",
    "                )\n",
    "                logger.info(f\"[S3] Uploaded Demultiplex_Stats ‚Üí s3://{bucket_name}/{demux_s3_key}\")\n",
    "                status_row[\"demux\"] = \"uploaded\"\n",
    "                summary[\"demux_uploaded\"] += 1\n",
    "            else:\n",
    "                logger.info(f\"[ICA] Demultiplex_Stats.csv not found for {reference}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[ICA] Error processing Demultiplex_Stats for {reference}: {e}\", exc_info=True)\n",
    "            status_row[\"demux\"] = \"error\"\n",
    "\n",
    "        # --- Quality_Metrics.csv ---\n",
    "        try:\n",
    "            quality_path = f\"/ilmn-analyses/{reference}/output/Reports/Quality_Metrics.csv\"\n",
    "            quality_items = lookup_file_by_path(quality_path)\n",
    "\n",
    "            if quality_items:\n",
    "                quality_file_id = quality_items[0][\"data\"][\"id\"]\n",
    "                raw_bytes = download_csv_bytes(quality_file_id)\n",
    "                out_bytes = add_id_library(raw_bytes, id_library)\n",
    "\n",
    "                qs_s3_key = f\"illumina/qs/{quality_file_id}/Quality_Metrics.csv\"\n",
    "                s3_hook.load_bytes(\n",
    "                    bytes_data=out_bytes,\n",
    "                    key=qs_s3_key,\n",
    "                    bucket_name=\"bgsi-data-dwh-bronze\",\n",
    "                    replace=True\n",
    "                )\n",
    "                logger.info(f\"[S3] Uploaded Quality_Metrics ‚Üí s3://bgsi-data-dwh-bronze/{qs_s3_key}\")\n",
    "                status_row[\"quality\"] = \"uploaded\"\n",
    "                summary[\"quality_uploaded\"] += 1\n",
    "            else:\n",
    "                logger.info(f\"[ICA] Quality_Metrics.csv not found for {reference}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[ICA] Error processing Quality_Metrics for {reference}: {e}\", exc_info=True)\n",
    "            status_row[\"quality\"] = \"error\"\n",
    "\n",
    "        summary[\"analyses_processed\"] += 1\n",
    "        summary[\"per_analysis\"].append(status_row)\n",
    "\n",
    "    logger.info(\n",
    "        f\"[DONE] considered={summary['analyses_considered']}, \"\n",
    "        f\"processed={summary['analyses_processed']}, \"\n",
    "        f\"demux_uploaded={summary['demux_uploaded']}, \"\n",
    "        f\"quality_uploaded={summary['quality_uploaded']}\"\n",
    "    )\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93f73e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
